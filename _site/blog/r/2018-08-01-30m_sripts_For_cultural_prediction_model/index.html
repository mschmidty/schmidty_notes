<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Cultural Model R Scripts</title>
    <meta name="description" content="">
    <link rel="stylesheet" href="/css/main.css">
  </head>
  <body>
    <header>
      
    </header>

    <main>
      <article class="post-content">
  <header class="post-header">
    <h1 class="post-title">Cultural Model R Scripts</h1>
    <div class="post-meta">
      <time datetime="Invalid DateTime" class="post-time">August 01, 2018</time>
      <span>| tags:</span>
      <ul class="tags-list post-tag-list">
      
        
        <li><a href="/tags/r/" class="tag-list-tag">R</a></li>
      
        
        <li><a href="/tags/jekyll-update/" class="tag-list-tag">jekyll update</a></li>
      
      </ul>
    </div>
  </header>
  <p>The following are scripts that I used to make a cultural prediction model.  It uses topographic, hydrologic and biological GIS information to predict areas where arc sites likely occur on the landscape.</p>
<h2>Load Libraries</h2>
<pre><code class="language-{r}">library(tidyverse)
library(randomForest)
</code></pre>
<h2>Read Data</h2>
<p>I made the dataset loaded here in another R file. The file loaded here was created using a 30m Digital Elevation Model.  The elevation model was used to calculate slope, aspect, flow direction, TPI, TRI, and roughness.</p>
<pre><code class="language-{r}">data&lt;-readRDS(&quot;rData/master_datasets/master_07172018.rds&quot;)
data
</code></pre>
<h2>Remove NAs</h2>
<p>It may be more appropriate to impute NAs vs remove them completely, but there are very few NAs only at the spacial edge of the model.</p>
<pre><code class="language-{r}">data_cl&lt;- data%&gt;% filter(!is.na(Slope)| !is.na(Aspect))%&gt;%
  filter(!is.na(TPI)| !is.na(TRI))##%&gt;%
</code></pre>
<h2>Convert character to factors</h2>
<p>Random Forests can't handle characters so here we convert the characters to factors.</p>
<pre><code class="language-{r}">data_cl$BPS_NAME&lt;-as.factor(data_cl$BPS_NAME)
data_cl$GROUPVEG&lt;-as.factor(data_cl$GROUPVEG)
data_cl$GROUPNAME&lt;-as.factor(data_cl$GROUPNAME)
</code></pre>
<h2>Separate the dataset into surveyed and non surveyed datasets</h2>
<p>The surveyed sites sill be used to train the model because we know there outcome.  The non-surveyed sites will have the model be applied to them.</p>
<pre><code class="language-{r}">surveyed&lt;-filter(data_cl, Survey==&quot;Yes&quot;)
noSurvey&lt;-filter(data_cl, Survey==&quot;No&quot;)
</code></pre>
<h2>Separate the surveyed dataset into has arch site vs does not have candy.</h2>
<p>Arch sites are coded from 1 to 6
Here we are selecting prehistoric sites (1) and multi sites (2).
The sites removed are:
3 - Historic
4 - NA
5 - Proto
6 - Historic</p>
<pre><code class="language-{r}">surveyed$prehistoric_test&lt;- ifelse(surveyed$RES_TYPE_Raster == 1| surveyed$RES_TYPE_Raster == 2, 1,2)
surveyed$prehistoric_test[is.na(surveyed$prehistoric_test)]&lt;-2
</code></pre>
<h2>Separate the dataset into train and test</h2>
<p>Separate the dataset randomly into 70:30 split.  The resulting train dataset will be used to make the model and the resulting test dataset will be used to test the model.</p>
<pre><code class="language-{r}">train&lt;-sample_frac(surveyed, 0.7)
sid&lt;-as.numeric(rownames(train))
test&lt;-surveyed[-sid,]
filter(train, prehistoric_test==1)
train
</code></pre>
<h2>Determine the number of sites vs non-sites`</h2>
<pre><code class="language-{r}">table(test$prehistoric_test)
</code></pre>
<h2>Run Random Forests</h2>
<p>The following runs the model and assigns the model to fit.</p>
<pre><code class="language-{r}">set.seed(415)

ptm&lt;- proc.time()

fit&lt;-randomForest(as.factor(prehistoric_test)~ Flowdir +      BPS_NAME + DEM + Slope + Aspect + GROUPNAME + INTR_NEAR +      PRNL_NEAR + MuleDeer_M + Elk_Mirgat + BigHorn_Mi + Prong_Migr +      ElkWinConc + TRI + TPI + Roughness + ElkSumConc + TurkeyProd +      TurkWinCon + BHS_SumCon + BHS_Prod + BHS_WinCon,
                  data=train,
                  importance=TRUE,
                  sampsize=c(6287,6287), ##This, sampsize, is extremely important. Random forests performs poorly with uneven classes (ie class 1 has a count of 500 and class 2 has a cound of 10,000).  We need to even out the sample sizes in the model.  How this is by taking the value with the lowest count and setting the second value to same or different proportion, in this case we only have 1029 observations that have candy.  If you wanted an evenly weighted sample size/weight you would set the sampsize to `sampsize=c(1029,1029)`.  In this case we want to overpredict candy so we give it a greater weight than the non candy sites.
                  mtry=12,
                  ntree=750)
proc.time() - ptm
varImpPlot(fit)
print(fit)
importance(fit)
</code></pre>
<h2>Find the results</h2>
<p>The following applies the model <code>fit</code> to the <code>test</code> data and then determines how well it predicted both the candy sites and the non-cany sites.</p>
<pre><code class="language-{r}">Prediction&lt;-predict(fit, test)
prediction_test&lt;- transform(test, predict=Prediction)
##prediction_test
prediction_test&lt;-prediction_test %&gt;%
  mutate(success=if_else(prehistoric_test==predict, 1, 0))

probability &lt;- predict(fit, test, type=&quot;prob&quot;)
prob1&lt;- probability[,1]
prob2&lt;- probability[,2]
prediction_test&lt;- transform(prediction_test, prob1=prob1)
prediction_test&lt;- transform(prediction_test, prob2=prob2)

arc_predict&lt;-filter(prediction_test, prehistoric_test==1)
no_predict&lt;-filter(prediction_test, prehistoric_test==2)
##head(prediction_test)
count_arc_predict&lt;- table(test$prehistoric_test)
count_arc_predict

sum(arc_predict$success)/count_arc_predict[names(count_arc_predict)==1]*100
sum(no_predict$success)/count_arc_predict[names(count_arc_predict)==2]*100


##arc_predict
##no_predict_predict[names(count_arc_predict)==2]*100

sum(prediction_test$success)/10639*100
</code></pre>
<h2>Predict the whole field office.</h2>
<pre><code class="language-{r}">final_predict&lt;-predict(fit, data_cl)
table(final_predict)
data_cl_prediction&lt;-transform(data_cl, predict=final_predict)

final_probability&lt;-predict(fit, data_cl, type=&quot;prob&quot;)
prob1&lt;- final_probability[,1]
prob2&lt;- final_probability[,2]

data_cl_prediction&lt;- transform(data_cl_prediction, prob1=prob1)
data_cl_prediction&lt;- transform(data_cl_prediction, prob2=prob2)
head(data_cl_prediction)
</code></pre>
<h2>Save points</h2>
<p>Save variables x, y and probability.  The x and y coordinates will be converted into a raster in Arc Map.</p>
<pre><code class="language-{r}">export_data_cl&lt;- dplyr::select(data_cl_prediction, x, y, predict:prob2 )
write_csv(export_data_cl,&quot;rData/predicted_pointsV2.csv&quot;)
</code></pre>

</article>

    </main>

    <footer></footer>

    <!-- Current page: /blog/r/2018-08-01-30m_sripts_For_cultural_prediction_model/ -->
  </body>
</html>